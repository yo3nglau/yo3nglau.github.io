<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Home on yo3nglau academic website</title>
    <link>/</link>
    <description>Recent content in Home on yo3nglau academic website</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 01 Jun 2023 00:00:00 +0000</lastBuildDate><atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>王汎森，如果讓我重做一次研究生</title>
      <link>/post/%E7%8E%8B%E6%B1%8E%E6%A3%AE%E5%A6%82%E6%9E%9C%E8%AE%93%E6%88%91%E9%87%8D%E5%81%9A%E4%B8%80%E6%AC%A1%E7%A0%94%E7%A9%B6%E7%94%9F/</link>
      <pubDate>Thu, 01 Jun 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/%E7%8E%8B%E6%B1%8E%E6%A3%AE%E5%A6%82%E6%9E%9C%E8%AE%93%E6%88%91%E9%87%8D%E5%81%9A%E4%B8%80%E6%AC%A1%E7%A0%94%E7%A9%B6%E7%94%9F/</guid>
      <description>前言 这篇文章是王汎森院士在 2005 年于中央研究院历史语言研究所完成的，主题是呈现自己对硕士、博士两个阶段的经验分享。
感想 由接受知识到创造知识，博士论文是个人所有武功的总集合，要提出一个重要的问题，跨越一个重要的领域，对人类的知识有所创新。去挑战原来的自己，不一定能做到的事情。写论文，清楚是最高指导原则。论文最关键的是那一个统摄性的重要概念，往往需要跨越学科去发现。要寻找一个有意义、有延展性、可控制、可以经营的问题，而且不要太难。唯有选定题目以后，你的所有训练跟努力才有价值。一天总也要留一些时间好好思考、慢慢沉淀。学习跳到比你所看到的东西更高一点的层次去思考。
摘录 注：这一部分摘取触发笔者的语句，为句意通顺，可能存在适当删改。
王汎森先生在美国获得博士学位的毕业证书上有这样的拉丁文：恭喜你对人类的知识有所创新，因此授予你这个学位。 作为研究生，不只是要完全乐在其中，更要从而接受各种有趣的知识，进入制造知识的阶段，也就是说你的论文应该有所创新。由接受知识到创造知识，是身为一个研究生最大的特色。 体认自己不再是个容器，等着老师把某些东西倒在茶杯里，而是要开始逐步发展和开发自己。 到了硕士生和博士生，有一个最终的目的，就是要完成论文，那篇论文是你个人所有武功的总集合，所有这时候必须要有个问题取向的学习。 提出一个重要的问题，跨越一个重要的领域，将决定你未来的成败。 必须选定一个有兴趣与关注的主题为出发点，来探究这些知识，产生有机的循环。 学习是一种 self-help。 Learn how to learn。 慢慢学习把目标放在一个标准上，而这一个标准就是你将来要完成硕士或博士论文，这一篇论文可能要和全世界做同一件问题的人相比较，你的标准不能单单只是放在旁边几个人而已，而应该是要放在领域的普遍人里面。 search 是寻找，而 research 是再寻找。 学生呈现被动或是懈怠的时候，会用毛泽东的「革命不是请客吃饭」来讲：「作研究生不是请客吃饭」。 不停的念书、不停的报告，不停的逼自己吸收，这是进入一个陌生的领域最快，又最方便的办法。运用这样的方式慢慢训练，有一天不再研究它时，发现自己仍然有自我生产及蓄发的能力，这个学问大概是怎么样的轮廓，碰到问题也有能力去查询相关的资料，努力让自己的学习产生自发的延展性是很重要的。 警惕沉浸在细节里不能自拔，进而失去全景，导致见树不见林。 为了完成一个大的、完整的、有机的架构模型，必须要从小规模的篇幅慢慢练习，这是一个最有效的办法。 写论文时很重要的一点是，文笔一定要清楚，不要花俏、不必漂亮，清楚是最高指导原则。 文采像个人的生命一样，英文叫 style，style 本身就像个人一样带有一点点天生。 要每隔一段时间就给自己一个挑战，挑战一个你做不到的东西，你不一定要求自己每次都能顺利克服那个挑战，但是要努力去尝试。去挑战原来的你，不一定能做到的事情。不过也要切记，硕士生是刚开始进入这一个领域的新手，如果一开始问题太小，或是问题大到不能控制，都会造成以后研究的困难。 硕士跟博士是一个训练的过程，硕士跟博士不是写经典之作的过程。不一定要可以强求，要有这是一个训练过程的信念，应该清楚知道从哪里开始，也要知道从哪里放手，不要无限的追下去。是自然而然形成的，应该要坚定的告诉自己，所要完成的是一份结构严谨、论述清楚与言之有物的论文，不要一开始就期待它是经典之作。 一定要构建一个属于自己的知识树，才能在那棵树挂相关的东西，但千万不要不断的挂不相关的东西，而且要慢慢地舍掉一些挂不上去的东西，再随着你的问题跟关心的领域，让这棵知识树有主干和枝叶。 生也有涯，知也无涯，阅读太多不是自己所关心的领域的知识，它对于你来说只是一地的散钱。 应该把跨学科的学习当作是一件很重要的事，但是跨学科涉及的东西必须要对你这棵知识树有助益，要学会到别的领域稍微偷打几枪，到别的领域去摄取一些概念，对于本身关心的问题产生另一种不同的启发，可是不要泛滥无所归。近几十年来，人们发现不管是科学或人文，最有创新的部分是发生在学科交会的地方。 常常一篇硕士论文或博士论文最重要、最关键的，是那一个统摄性的重要概念，而通常你在本学科里面抓不到，是因为你已经泡在这个学科里面太久了，你已经拿着手电筒在这个小仓库里面照来照去照太久了，而忘了还有别的东西可以更好解释你这些材料的现象，不过这些东西可遇而不可求。 对一个硕士生或博士生来说，如果选错了题目，就是失败，题目选对了，还有百分之七十胜利的机会。这个问题值得研一、博一的学生好好思考。你的第一年其实就是要花在这上面，你要不断的跟老师商量寻找一个有意义、有延展性的问题，而且不要太难。 读、写任何语言一定要练习到你能带着三分随意，那时候你才可以说对于这一个语言完全理解与静熟，如果你还无法达到三分的随意，就表示你还在摸索。 唯有选定题目以后，你的所有训练跟努力才有价值。选题的工作要尽早做，所选的题目所要处理的材料最好要集中，不要太分散。如果你的材料太不集中，读书或看资料可能就要花掉你大部分的时间，让你没有余力思考。 一个最基本的训练，就是平时不管你写一万字、三万字、五万字都要养成遵照学术规范的习惯，要让他自然天成。要尽早学会中英文的写作规范，慢慢练习，最后随性下笔，就能写出符合规范的文章。 切记不重要的不要花很多时间去看，生活在信息泛滥的时代，要能有所取舍。 要给自己保留一些思考的时间。一个论文能不能出神入化、能不能引人入胜，很重要的是在现象之上作概念性的思考。 conceptualize 你所看到的东西，真切去了解，你所看到的是什么？整体意义是什么？整体的轮廓是什么？千万不要被枝节淹没，虽然枝节是你最重要的开始，但是你一天总也要留一些时间好好思考、慢慢沉淀。在被很多材料和枝节淹没的时候，要适时跳出来想一想，所看到的东西有哪些意义？这个意义有没有广泛连结到更大层面的知识价值。 至少每天要留个三十分钟、一小时思考，想一想你看到了什么？学习跳到比你所看到的东西更高一点的层次去思考。 好好的把一位大师的作品读完，开始模仿和学习他，是入门最好的方法，逐步的，你也开写出自己的东西。 我们的人生是两只脚，我们不是靠一只脚走路，另外一只脚是要学习培养一、两种兴趣或嗜好，用来好好的调解或是排遣自己。 一定要有很大的责任感，去写出好的东西，如果责任感还不够强，还要有一个罪恶感，你会觉得如果今天如果没有好好做几个小时的工作的话，会有很大的罪恶感。 一个卓越的大学、一个好的大学、一个好的学习环境，表示里面有一个共同关心的焦点，如果没有的话，这个学校就不可能成为好的大学。 待探索内容 美国普林斯顿大学、英国剑桥大学、美国柏克莱大学
人文科学、社会科学、自然科学
蒋百里、傅斯年
Pavarotti
参考文献 论文
Previous Next &amp;nbsp; &amp;nbsp; / [pdf] View the PDF file here. </description>
    </item>
    
    <item>
      <title>htop Command in Linux</title>
      <link>/post/htop-command-in-linux/</link>
      <pubDate>Fri, 26 May 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/htop-command-in-linux/</guid>
      <description>Name htop - interactive process viewerSyntax htop [-dChustv]Description htop command in Linux system is a command line utility that allows the user to interactively monitor the system’s vital resources or server’s processes in real time. htop is a newer program compared to top command, and it offers many improvements over top command. htop supports mouse operation, uses color in its output and gives visual indications about processor, memory and swap usage.</description>
    </item>
    
    <item>
      <title>(arXiv 22&#39;) SymFormer- End-to-end symbolic regression using transformer-based architecture</title>
      <link>/post/arxiv-22-symformer-end-to-end-symbolic-regression-using-transformer-based-architecture/</link>
      <pubDate>Thu, 25 May 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/arxiv-22-symformer-end-to-end-symbolic-regression-using-transformer-based-architecture/</guid>
      <description>Overview Motivation Many real-world problems can be naturally described by mathematical formulas. The task of finding formulas from a set of observed inputs and outputs is called symbolic regression.
Neural networks have been applied to symbolic regression, among which the transformer-based ones seem to be the most promising. However, the main drawback of transformers is that they generate formulas without numerical constants, which have to be optimized separately, so yielding suboptimal results.</description>
    </item>
    
    <item>
      <title>(CVPR 23&#39;) RGB no more- Minimally-decoded JPEG Vision Transformers</title>
      <link>/post/cvpr-23-rgb-no-more-minimally-decoded-jpeg-vision-transformers/</link>
      <pubDate>Thu, 25 May 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/cvpr-23-rgb-no-more-minimally-decoded-jpeg-vision-transformers/</guid>
      <description>Overview Motivation Most neural networks for computer vision are designed to infer using RGB images. However, these RGB images are commonly encoded in JPEG before saving to disk; decoding them imposes an unavoidable overhead for RGB networks.
&amp;ldquo;Figure 2. Process of applying 8 × 8 DCT to the input image. The input image is sliced into 8 × 8 patches and the DCT is applied to each patch. The DCT bases are shown on the right.</description>
    </item>
    
    <item>
      <title>Clear Specific Website Cache in Google Chrome</title>
      <link>/post/clear-specific-website-cache-in-google-chrome/</link>
      <pubDate>Tue, 23 May 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/clear-specific-website-cache-in-google-chrome/</guid>
      <description>Method Press F12 to reach developer toolbox Choose Network Disable cache Press and hold reload button on the left top of Chrome Choose Empty Cache and Hard Reload </description>
    </item>
    
    <item>
      <title>Categories and Tags in Blogs</title>
      <link>/post/categories-and-tags-in-blogs/</link>
      <pubDate>Mon, 22 May 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/categories-and-tags-in-blogs/</guid>
      <description>TLDR Categories are broad topics that help you organize your blog posts, and help readers find the information they’re seeking on your site.
Tags are a simple way to drill down on the topic of any given blog post that’s part of a category.
Description These two words may be used interchangeably, but they are not the same thing. The difference is simple: A category is a broad topic you cover in your blog.</description>
    </item>
    
    <item>
      <title>git add</title>
      <link>/post/git-add/</link>
      <pubDate>Mon, 22 May 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/git-add/</guid>
      <description>Name git-add - Add file contents to the indexDescription This command updates the index using the current content found in the working tree, to prepare the content staged for the next commit.
The &amp;ldquo;index&amp;rdquo; holds a snapshot of the content of the working tree, and it is this snapshot that is taken as the contents of the next commit.
Thus after making any changes to the working tree, and before running the commit command, you must use the add command to add any new or modified files to the index.</description>
    </item>
    
    <item>
      <title>git commit</title>
      <link>/post/git-commit/</link>
      <pubDate>Mon, 22 May 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/git-commit/</guid>
      <description>Name git-commit - Record changes to the repositoryDescription Create a new commit containing the current contents of the index and the given log message describing the changes. The new commit is a direct child of HEAD, usually the tip of the current branch, and the branch is updated to point to it.
The content to be committed can be specified in several ways:
by using git-add to incrementally &amp;ldquo;add&amp;rdquo; changes to the index before using the commit command (Note: even modified files must be &amp;ldquo;added&amp;rdquo;); &amp;hellip; Options -a, --all</description>
    </item>
    
    <item>
      <title>git status</title>
      <link>/post/git-status/</link>
      <pubDate>Mon, 22 May 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/git-status/</guid>
      <description>Name git-status - Show the working tree statusDescription Displays paths that have differences between the index file and the current HEAD commit, paths that have differences between the working tree and the index file, and paths in the working tree that are not tracked by Git. The first are what you would commit by running git commit; the second and third are what you could commit by running git add before running git commit.</description>
    </item>
    
    <item>
      <title>MINC file format</title>
      <link>/post/minc-file-format/</link>
      <pubDate>Mon, 22 May 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/minc-file-format/</guid>
      <description>TLDR The MINC refers to a specific file format and toolbox dealing with multiple file formats from varying scanners and research groups.
Description The MINC file format and toolbox was originally conceived, written and released by Peter Neelin in 1992 due to the frustrations of dealing with multiple file formats from varying scanners and research groups.
In the ensuing years many associated tools (image registration, normalization, visualization, etc.) were written and have also been released.</description>
    </item>
    
    <item>
      <title>(ICCV 21&#39;) Calibrating Concepts and Operations- Towards Symbolic Reasoning on Real Images</title>
      <link>/post/iccv-21-calibrating-concepts-and-operations-towards-symbolic-reasoning-on-real-images/</link>
      <pubDate>Wed, 17 May 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/iccv-21-calibrating-concepts-and-operations-towards-symbolic-reasoning-on-real-images/</guid>
      <description>Overview &amp;ldquo;Figure 1: Statistics and examples from the synthetic CLEVR dataset and the real GQA dataset. Compared to the synthetic dataset, VQA on real data needs to deal with long-tail concept distribution and uneven importance of reasoning steps.&amp;rdquo;
Motivation While neural symbolic methods demonstrate impressive performance in visual question answering on synthetic images, their performance suffers on real images. This work identifies that the long-tail distribution of visual concepts and unequal importance of reasoning steps in real data are the two key obstacles that limit the models’ real-world potentials.</description>
    </item>
    
    <item>
      <title>(ICLR 19&#39; oral) THE NEURO-SYMBOLIC CONCEPT LEARNER- INTERPRETING SCENES, WORDS, AND SENTENCES FROM NATURAL SUPERVISION</title>
      <link>/post/iclr-19-oral-the-neuro-symbolic-concept-learner-interpreting-scenes-words-and-sentences-from-natural-supervision/</link>
      <pubDate>Wed, 17 May 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/iclr-19-oral-the-neuro-symbolic-concept-learner-interpreting-scenes-words-and-sentences-from-natural-supervision/</guid>
      <description>Overview &amp;ldquo;Figure 7: An example image-question pair from the VQS dataset and the corresponding execution trace of NS-CL.&amp;rdquo;
This work proposes the Neuro-Symbolic Concept Learner (NS-CL), a model that learns visual concepts, words, and semantic parsing of sentences without explicit supervision on any of them; instead, the model learns by simply looking at images and reading paired questions and answers. The proposed model builds an object-based scene representation and translates sentences into executable, symbolic programs.</description>
    </item>
    
    <item>
      <title>(NeurIPS 22&#39;) End-to-end symbolic regression with transformers</title>
      <link>/post/neurips-22-end-to-end-symbolic-regression-with-transformers/</link>
      <pubDate>Wed, 17 May 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/neurips-22-end-to-end-symbolic-regression-with-transformers/</guid>
      <description>Overview Framework Unfamiliar knowledge Note: May include buzz word and potential literature.
Resources Paper, Code
Elementary drafts Note: May contain Chinese. This section will disappear once all drafts are embellished.
collapsed contentssomething一些草稿</description>
    </item>
    
    <item>
      <title>About me</title>
      <link>/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/about/</guid>
      <description>I&amp;rsquo;m studying as a Ph.D. candidate at Tsinghua University of China.
I&amp;rsquo;m interested in deep learning and computer vision.
I know a bit about action segmentation and Transformers.
Currently, I want to make some progress in the video realm.</description>
    </item>
    
  </channel>
</rss>
