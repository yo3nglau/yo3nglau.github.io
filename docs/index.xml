<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Home on yo3nglau academic website</title>
    <link>/</link>
    <description>Recent content in Home on yo3nglau academic website</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 25 May 2023 00:00:00 +0000</lastBuildDate><atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>(arXiv 22&#39;) SymFormer- End-to-end symbolic regression using transformer-based architecture</title>
      <link>/post/arxiv-22-rgb-no-more-minimally-decoded-jpeg-vision-transformers/</link>
      <pubDate>Thu, 25 May 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/arxiv-22-rgb-no-more-minimally-decoded-jpeg-vision-transformers/</guid>
      <description>Overview Motivation Many real-world problems can be naturally described by mathematical formulas. The task of finding formulas from a set of observed inputs and outputs is called symbolic regression.
Neural networks have been applied to symbolic regression, among which the transformer-based ones seem to be the most promising. However, the main drawback of transformers is that they generate formulas without numerical constants, which have to be optimized separately, so yielding suboptimal results.</description>
    </item>
    
    <item>
      <title>(arXiv 22&#39;) SymFormer- End-to-end symbolic regression using transformer-based architecture</title>
      <link>/post/cvpr-23-symformer-end-to-end-symbolic-regression-using-transformer-based-architecture-copy/</link>
      <pubDate>Thu, 25 May 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/cvpr-23-symformer-end-to-end-symbolic-regression-using-transformer-based-architecture-copy/</guid>
      <description>Overview Motivation Many real-world problems can be naturally described by mathematical formulas. The task of finding formulas from a set of observed inputs and outputs is called symbolic regression.
Neural networks have been applied to symbolic regression, among which the transformer-based ones seem to be the most promising. However, the main drawback of transformers is that they generate formulas without numerical constants, which have to be optimized separately, so yielding suboptimal results.</description>
    </item>
    
    <item>
      <title>Clear Specific Website Cache in Google Chrome</title>
      <link>/post/clear-specific-website-cache-in-google-chrome/</link>
      <pubDate>Tue, 23 May 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/clear-specific-website-cache-in-google-chrome/</guid>
      <description>Method Press F12 to reach developer toolbox Choose Network Disable cache Press and hold reload button on the left top of Chrome Choose Empty Cache and Hard Reload </description>
    </item>
    
    <item>
      <title>Categories and Tags in Blogs</title>
      <link>/post/categories-and-tags-in-blogs/</link>
      <pubDate>Mon, 22 May 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/categories-and-tags-in-blogs/</guid>
      <description>TLDR Categories are broad topics that help you organize your blog posts, and help readers find the information they’re seeking on your site.
Tags are a simple way to drill down on the topic of any given blog post that’s part of a category.
Description These two words may be used interchangeably, but they are not the same thing. The difference is simple: A category is a broad topic you cover in your blog.</description>
    </item>
    
    <item>
      <title>git add</title>
      <link>/post/git-add/</link>
      <pubDate>Mon, 22 May 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/git-add/</guid>
      <description>Name git-add - Add file contents to the index
Description This command updates the index using the current content found in the working tree, to prepare the content staged for the next commit.
The &amp;ldquo;index&amp;rdquo; holds a snapshot of the content of the working tree, and it is this snapshot that is taken as the contents of the next commit.
Thus after making any changes to the working tree, and before running the commit command, you must use the add command to add any new or modified files to the index.</description>
    </item>
    
    <item>
      <title>git commit</title>
      <link>/post/git-commit/</link>
      <pubDate>Mon, 22 May 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/git-commit/</guid>
      <description>Name git-commit - Record changes to the repository
Description Create a new commit containing the current contents of the index and the given log message describing the changes. The new commit is a direct child of HEAD, usually the tip of the current branch, and the branch is updated to point to it.
The content to be committed can be specified in several ways:
by using git-add to incrementally &amp;ldquo;add&amp;rdquo; changes to the index before using the commit command (Note: even modified files must be &amp;ldquo;added&amp;rdquo;); &amp;hellip; Options -a, --all</description>
    </item>
    
    <item>
      <title>git status</title>
      <link>/post/git-status/</link>
      <pubDate>Mon, 22 May 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/git-status/</guid>
      <description>Name git-status - Show the working tree status
Description Displays paths that have differences between the index file and the current HEAD commit, paths that have differences between the working tree and the index file, and paths in the working tree that are not tracked by Git. The first are what you would commit by running git commit; the second and third are what you could commit by running git add before running git commit.</description>
    </item>
    
    <item>
      <title>MINC file format</title>
      <link>/post/minc-file-format/</link>
      <pubDate>Mon, 22 May 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/minc-file-format/</guid>
      <description>TLDR The MINC refers to a specific file format and toolbox dealing with multiple file formats from varying scanners and research groups.
Description The MINC file format and toolbox was originally conceived, written and released by Peter Neelin in 1992 due to the frustrations of dealing with multiple file formats from varying scanners and research groups.
In the ensuing years many associated tools (image registration, normalization, visualization, etc.) were written and have also been released.</description>
    </item>
    
    <item>
      <title>(ICCV 21&#39;) Calibrating Concepts and Operations- Towards Symbolic Reasoning on Real Images</title>
      <link>/post/iccv-21-calibrating-concepts-and-operations-towards-symbolic-reasoning-on-real-images/</link>
      <pubDate>Wed, 17 May 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/iccv-21-calibrating-concepts-and-operations-towards-symbolic-reasoning-on-real-images/</guid>
      <description>Overview &amp;ldquo;Figure 1: Statistics and examples from the synthetic CLEVR dataset and the real GQA dataset. Compared to the synthetic dataset, VQA on real data needs to deal with long-tail concept distribution and uneven importance of reasoning steps.&amp;rdquo;
Motivation While neural symbolic methods demonstrate impressive performance in visual question answering on synthetic images, their performance suffers on real images. This work identifies that the long-tail distribution of visual concepts and unequal importance of reasoning steps in real data are the two key obstacles that limit the models’ real-world potentials.</description>
    </item>
    
    <item>
      <title>(ICLR 19&#39; oral) THE NEURO-SYMBOLIC CONCEPT LEARNER- INTERPRETING SCENES, WORDS, AND SENTENCES FROM NATURAL SUPERVISION</title>
      <link>/post/iclr-19-oral-the-neuro-symbolic-concept-learner-interpreting-scenes-words-and-sentences-from-natural-supervision/</link>
      <pubDate>Wed, 17 May 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/iclr-19-oral-the-neuro-symbolic-concept-learner-interpreting-scenes-words-and-sentences-from-natural-supervision/</guid>
      <description>Overview &amp;ldquo;Figure 7: An example image-question pair from the VQS dataset and the corresponding execution trace of NS-CL.&amp;rdquo;
This work proposes the Neuro-Symbolic Concept Learner (NS-CL), a model that learns visual concepts, words, and semantic parsing of sentences without explicit supervision on any of them; instead, the model learns by simply looking at images and reading paired questions and answers. The proposed model builds an object-based scene representation and translates sentences into executable, symbolic programs.</description>
    </item>
    
    <item>
      <title>(NeurIPS 22&#39;) End-to-end symbolic regression with transformers</title>
      <link>/post/neurips-22-end-to-end-symbolic-regression-with-transformers/</link>
      <pubDate>Wed, 17 May 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/neurips-22-end-to-end-symbolic-regression-with-transformers/</guid>
      <description>Overview Framework Unfamiliar knowledge Note: May include buzz word and potential literature.
Resources Paper, Code
Elementary drafts Note: May contain Chinese. This section will disappear once all drafts are embellished.
collapsed contentssomething一些草稿</description>
    </item>
    
    <item>
      <title>About me</title>
      <link>/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/about/</guid>
      <description>I&amp;rsquo;m studying as a Ph.D. candidate at Tsinghua University of China.
I&amp;rsquo;m interested in deep learning and computer vision.
I know a bit about action segmentation and Transformers.
Currently, I want to make some progress in the video realm.</description>
    </item>
    
  </channel>
</rss>
