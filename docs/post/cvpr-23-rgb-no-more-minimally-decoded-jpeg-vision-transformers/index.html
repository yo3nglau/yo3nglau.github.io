<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>(CVPR 23&#39;) RGB no more- Minimally-decoded JPEG Vision Transformers | yo3nglau academic website</title>
    <link rel="stylesheet" href='/css/style.css' />
    <link rel="stylesheet" href='/css/fonts.css' />
    <link href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.5.1/styles/github.min.css" rel="stylesheet">
  </head>

  <body>
    <nav>
    <ul class="menu">
      
      <li><a href="/">Home</a></li>
      
      <li><a href="/about/">About</a></li>
      
      <li><a href="/categories/">Categories</a></li>
      
      <li><a href="/tags/">Tags</a></li>
      
    </ul>
    <hr/>
    </nav>

<div class="article-meta">
<h1><span class="title">(CVPR 23&rsquo;) RGB no more- Minimally-decoded JPEG Vision Transformers</span></h1>
<h2 class="author">yo3nglau</h2>
<h2 class="date">2023/05/25</h2>
<p class="terms">
  
  
  Categories: <a href="/categories/skimmed-papers">Skimmed Papers</a> 
  
  
  
  Tags: <a href="/tags/transformer">Transformer</a> <a href="/tags/cvpr">CVPR</a> 
  
  
</p>
</div>


<nav id="TableOfContents">
  <ul>
    <li><a href="#overview">Overview</a>
      <ul>
        <li><a href="#motivation">Motivation</a></li>
        <li><a href="#resolution">Resolution</a></li>
      </ul>
    </li>
    <li><a href="#framework">Framework</a></li>
    <li><a href="#arguments">Arguments</a>
      <ul>
        <li><a href="#dct-inputs">DCT inputs</a></li>
        <li><a href="#augmentation">Augmentation</a></li>
      </ul>
    </li>
    <li><a href="#unfamiliar-knowledge">Unfamiliar knowledge</a></li>
    <li><a href="#resources">Resources</a></li>
    <li><a href="#elementary-drafts">Elementary drafts</a></li>
  </ul>
</nav>


<main>
<h2 id="overview">Overview</h2>
<h3 id="motivation">Motivation</h3>
<p>Most neural networks for computer vision are designed to infer using RGB images. However, these RGB images are commonly encoded in JPEG before saving to disk; <em>decoding them imposes an unavoidable overhead for RGB networks</em>.</p>
<p><img src="https://s1.ax1x.com/2023/05/25/p9beui6.png" alt=""></p>
<p>&ldquo;Figure 2. Process of applying 8 × 8 DCT to the input image. The input image is sliced into 8 × 8 patches and the DCT is applied to each patch. The DCT bases are shown on the right.&rdquo;</p>
<h3 id="resolution">Resolution</h3>
<p>This work focuses on training Vision Transformers <strong>directly from the encoded features of JPEG</strong>, which avoids most of the decoding overhead, accelerating data load. In addition, authors tackle <strong>data augmentation</strong> directly on these encoded features, which has not been explored in-depth for training in this setting.</p>
<h2 id="framework">Framework</h2>
<p><img src="https://s1.ax1x.com/2023/05/25/p9beKJK.png" alt=""></p>
<p>&ldquo;Figure 4. Proposed model architectures. We first collect 8×8 DCT blocks until it matches the patch size. Then, these blocks are embedded through the different architectures. Grouped architecture groups all of the collected blocks and embeds them together. Separate architecture embeds each block separately and mixes it. Concatenation architecture embeds <strong>Y</strong> and <strong>U</strong> separately and concatenates them.&rdquo;</p>
<p><img src="https://s1.ax1x.com/2023/05/25/p9beMRO.png" alt=""></p>
<p>&ldquo;Figure 1. Our proposed training process. The typical process requires full decoding as well as patch extraction to train. In contrast, our process does not since the DCT coefficients are already saved in block-wise fashion. As ViTs work on image patches, we can directly feed these coefficients to the network.&rdquo;</p>
<h2 id="arguments">Arguments</h2>
<h3 id="dct-inputs">DCT inputs</h3>
<p>Data is typically loaded by the CPU while the network runs on a GPU or other accelerator; more efficient data loading can thus <strong>reduce CPU bottlenecks</strong> and accelerate the entire pipeline.</p>
<p>Authors show that ViTs can be <strong>easily adapted to DCT inputs</strong> by modifying only the initial patch embedding layer and leaving the rest of the architecture unchanged.</p>
<h3 id="augmentation">Augmentation</h3>
<p>Some standard augmentations such as image rotation and shearing are costly to implement in DCT, so authors also introduce several new augmentations which are natural for DCT.</p>
<img src="https://s1.ax1x.com/2023/05/25/p9bemIx.png" style="zoom:80%;" />
<p>Figure 5. A visualization of different DCT augmentation types. Orange-colored coefficients are augmented and saved as bluecolored ones. The bottom two examples illustrate <em>Translate</em> and <em>Resize</em> augmentation.</p>
<h2 id="unfamiliar-knowledge">Unfamiliar knowledge</h2>
<p><strong>Note: May include buzz word and potential literature.</strong></p>
<p>JPEG files store image data using Huffman codes</p>
<p>discrete cosine transform (DCT)</p>
<p>luma data and chroma data</p>
<p>[Paper] Faster Neural Networks Straight from JPEG.</p>
<p>[Paper] Learning in the frequency domain.</p>
<p>[Paper] Randaugment: Practical automated data augmentation with a reduced search space.</p>
<p>video codecs</p>
<p>YCbCr color space</p>
<p>Run-length encoding(RLE)</p>
<h2 id="resources">Resources</h2>
<p><a href="https://arxiv.org/abs/2211.16421">Paper</a></p>
<h2 id="elementary-drafts">Elementary drafts</h2>
<p><strong>Note: May contain Chinese. This section will disappear once all drafts are embellished.</strong></p>
<details>
	<summary>collapsed contents</summary>
		add more details
</details>
<script type="text/javascript" src='/js/pdf-js/build/pdf.js'></script>

<style>
  #embed-pdf-container {
    position: relative;
    width: 100%;
    height: auto;
    min-height: 20vh;
     
  }
  
  .pdf-canvas {
    border: 1px solid black;
    direction: ltr;
    width: 100%;
    height: auto;
    display: none;
  }
  
  #the-canvas {
    border: 1px solid black;
    direction: ltr;
    width: 100%;
    height: auto;
    display: none;
  }
  
  
  .pdf-loadingWrapper {
    display: none;
    justify-content: center;
    align-items: center;
    width: 100%;
    height: 350px;
  }
  
  .pdf-loading {
    display: inline-block;
    width: 50px;
    height: 50px;
    border: 3px solid #d2d0d0;;
    border-radius: 50%;
    border-top-color: #383838;
    animation: spin 1s ease-in-out infinite;
    -webkit-animation: spin 1s ease-in-out infinite;
  }
  
  
  
  
  
  #overlayText {
    word-wrap: break-word;
    display: grid;
    justify-content: end;
  }
  
  #overlayText a {
    position: relative;
    top: 10px;
    right: 4px;
    color: #000;
    margin: auto;
    background-color: #eeeeee;
    padding: 0.3em 1em;
    border: solid 2px;
    border-radius: 12px;
    border-color: #00000030;
    text-decoration: none;
  }
  
  #overlayText svg {
    height: clamp(1em, 2vw, 1.4em);
    width:  clamp(1em, 2vw, 1.4em);
  }
  
  
  
  @keyframes spin {
    to { -webkit-transform: rotate(360deg); }
  }
  @-webkit-keyframes spin {
    to { -webkit-transform: rotate(360deg); }
  }
  </style><div class="embed-pdf-container" id="embed-pdf-container-a4585f76">
    <div class="pdf-loadingWrapper" id="pdf-loadingWrapper-a4585f76">
        <div class="pdf-loading" id="pdf-loading-a4585f76"></div>
    </div>
    <div id="overlayText">
      <a href="../../pdfs/RGB%20no%20more-%20Minimally-decoded%20JPEG%20Vision%20Transformers.pdf" aria-label="Download" download>
        <svg aria-hidden="true" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 18 18">
            <path d="M9 13c.3 0 .5-.1.7-.3L15.4 7 14 5.6l-4 4V1H8v8.6l-4-4L2.6 7l5.7 5.7c.2.2.4.3.7.3zm-7 2h14v2H2z" />
        </svg>
      </a>
    </div>
    <canvas class="pdf-canvas" id="pdf-canvas-a4585f76"></canvas>
</div>

<div class="pdf-paginator" id="pdf-paginator-a4585f76">
    <button id="pdf-prev-a4585f76">Previous</button>
    <button id="pdf-next-a4585f76">Next</button> &nbsp; &nbsp;
    <span>
      <span class="pdf-pagenum" id="pdf-pagenum-a4585f76"></span> / <span class="pdf-pagecount" id="pdf-pagecount-a4585f76"></span>
    </span>
    <a class="pdf-source" id="pdf-source-a4585f76" href="../../pdfs/RGB%20no%20more-%20Minimally-decoded%20JPEG%20Vision%20Transformers.pdf">[pdf]</a>
</div>

<noscript>
View the PDF file <a class="pdf-source" id="pdf-source-noscript-a4585f76" href="../../pdfs/RGB%20no%20more-%20Minimally-decoded%20JPEG%20Vision%20Transformers.pdf">here</a>.
</noscript>

<script type="text/javascript">
    (function(){
    var url = '..\/..\/pdfs\/RGB no more- Minimally-decoded JPEG Vision Transformers.pdf';

    var hidePaginator = "" === "true";
    var hideLoader = "" === "true";
    var selectedPageNum = parseInt("") || 1;

    
    var pdfjsLib = window['pdfjs-dist/build/pdf'];

    
    if (pdfjsLib.GlobalWorkerOptions.workerSrc == '')
      pdfjsLib.GlobalWorkerOptions.workerSrc = "\/" + 'js/pdf-js/build/pdf.worker.js';

    
    var pdfDoc = null,
        pageNum = selectedPageNum,
        pageRendering = false,
        pageNumPending = null,
        scale = 3,
        canvas = document.getElementById('pdf-canvas-a4585f76'),
        ctx = canvas.getContext('2d'),
        paginator = document.getElementById("pdf-paginator-a4585f76"),
        loadingWrapper = document.getElementById('pdf-loadingWrapper-a4585f76');


    
    showPaginator();
    showLoader();

    

    function renderPage(num) {
      pageRendering = true;
      
      pdfDoc.getPage(num).then(function(page) {
        var viewport = page.getViewport({scale: scale});
        canvas.height = viewport.height;
        canvas.width = viewport.width;

        
        var renderContext = {
          canvasContext: ctx,
          viewport: viewport
        };
        var renderTask = page.render(renderContext);

        
        renderTask.promise.then(function() {
          pageRendering = false;
          showContent();

          if (pageNumPending !== null) {
            
            renderPage(pageNumPending);
            pageNumPending = null;
          }
        });
      });

      
      document.getElementById('pdf-pagenum-a4585f76').textContent = num;
    }

    

    function showContent() {
      loadingWrapper.style.display = 'none';
      canvas.style.display = 'block';
    }

    

    function showLoader() {
      if(hideLoader) return
      loadingWrapper.style.display = 'flex';
      canvas.style.display = 'none';
    }

    

    function showPaginator() {
      if(hidePaginator) return
      paginator.style.display = 'block';
    }

    

    function queueRenderPage(num) {
      if (pageRendering) {
        pageNumPending = num;
      } else {
        renderPage(num);
      }
    }

    

    function onPrevPage() {
      if (pageNum <= 1) {
        return;
      }
      pageNum--;
      queueRenderPage(pageNum);
    }
    document.getElementById('pdf-prev-a4585f76').addEventListener('click', onPrevPage);

    

    function onNextPage() {
      if (pageNum >= pdfDoc.numPages) {
        return;
      }
      pageNum++;
      queueRenderPage(pageNum);
    }
    document.getElementById('pdf-next-a4585f76').addEventListener('click', onNextPage);

    

    pdfjsLib.getDocument(url).promise.then(function(pdfDoc_) {
      pdfDoc = pdfDoc_;
      var numPages = pdfDoc.numPages;
      document.getElementById('pdf-pagecount-a4585f76').textContent = numPages;

      
      if(pageNum > numPages) {
        pageNum = numPages
      }

      
      renderPage(pageNum);
    });
    })();
</script>


</main>

  <footer>
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.5.1/highlight.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.5.1/languages/r.min.js"></script>

<script>
hljs.configure({languages: []});
hljs.initHighlightingOnLoad();
</script>
  
  <hr/>
  © <a href="https://github.com/yo3nglau">yo3nglau</a> 2023 | <a href="https://gohugo.io/">Hugo</a> | <a href="https://github.com/yihui/hugo-xmin">XMin</a>
  
  </footer>
  </body>
</html>

