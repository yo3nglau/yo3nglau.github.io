<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>arXiv on yo3nglau academic website</title>
    <link>/tags/arxiv/</link>
    <description>Recent content in arXiv on yo3nglau academic website</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 25 May 2023 00:00:00 +0000</lastBuildDate><atom:link href="/tags/arxiv/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>(arXiv 22&#39;) SymFormer- End-to-end symbolic regression using transformer-based architecture</title>
      <link>/post/arxiv-22-rgb-no-more-minimally-decoded-jpeg-vision-transformers/</link>
      <pubDate>Thu, 25 May 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/arxiv-22-rgb-no-more-minimally-decoded-jpeg-vision-transformers/</guid>
      <description>Overview Motivation Many real-world problems can be naturally described by mathematical formulas. The task of finding formulas from a set of observed inputs and outputs is called symbolic regression.
Neural networks have been applied to symbolic regression, among which the transformer-based ones seem to be the most promising. However, the main drawback of transformers is that they generate formulas without numerical constants, which have to be optimized separately, so yielding suboptimal results.</description>
    </item>
    
    <item>
      <title>(arXiv 22&#39;) SymFormer- End-to-end symbolic regression using transformer-based architecture</title>
      <link>/post/cvpr-23-symformer-end-to-end-symbolic-regression-using-transformer-based-architecture-copy/</link>
      <pubDate>Thu, 25 May 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/cvpr-23-symformer-end-to-end-symbolic-regression-using-transformer-based-architecture-copy/</guid>
      <description>Overview Motivation Many real-world problems can be naturally described by mathematical formulas. The task of finding formulas from a set of observed inputs and outputs is called symbolic regression.
Neural networks have been applied to symbolic regression, among which the transformer-based ones seem to be the most promising. However, the main drawback of transformers is that they generate formulas without numerical constants, which have to be optimized separately, so yielding suboptimal results.</description>
    </item>
    
  </channel>
</rss>
